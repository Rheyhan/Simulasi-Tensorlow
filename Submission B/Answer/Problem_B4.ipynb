{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================================\n",
    "# PROBLEM B4\n",
    "#\n",
    "# Build and train a classifier for the BBC-text dataset.\n",
    "# This is a multiclass classification problem.\n",
    "# Do not use lambda layers in your model.\n",
    "#\n",
    "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
    "#\n",
    "# Desired accuracy and validation_accuracy > 91%\n",
    "# ==================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#const\n",
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc = pd.read_csv('https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode to ordinal\n",
    "replacer=dict(zip(bbc[\"category\"].unique(), list(range(len(bbc[\"category\"].unique())))))\n",
    "bbc[\"category\"]=bbc[\"category\"].replace(replacer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "training_sentences, validation_sentences, training_labels, validation_labels= train_test_split(bbc[\"text\"].to_numpy(), bbc[\"category\"].to_numpy(), train_size=training_portion, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the token\n",
    "tokenizer = Tokenizer(oov_token=oov_tok, num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(training_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paddedsequences(sentences):\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    return pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "training_pad_sequences=get_paddedsequences(training_sentences)\n",
    "validation_pad_sequences=get_paddedsequences(validation_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(the_padsequences, labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((the_padsequences, labels))\n",
    "    ds = ds.cache()\n",
    "    ds = ds.batch(32)\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = get_ds(training_pad_sequences, training_labels)\n",
    "val_ds = get_ds(validation_pad_sequences, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model=keras.Sequential([\n",
    "        keras.layers.Embedding(input_dim=vocab_size, input_length=max_length, output_dim=embedding_dim),\n",
    "        keras.layers.GlobalAvgPool1D(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),        \n",
    "        keras.layers.Dense(6, activation='softmax')\n",
    "    ])   \n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.sparse_categorical_crossentropy, metrics=\"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(thecallback, self).__init__()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logtrain, logval = logs[\"accuracy\"], logs[\"val_accuracy\"]\n",
    "        if logtrain > 0.91 and logval> 0.91:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 6s 92ms/step - loss: 1.7672 - accuracy: 0.2472 - val_loss: 1.7318 - val_accuracy: 0.2697\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6945 - accuracy: 0.2888 - val_loss: 1.6450 - val_accuracy: 0.3843\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.6183 - accuracy: 0.3056 - val_loss: 1.5723 - val_accuracy: 0.4517\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.5547 - accuracy: 0.3511 - val_loss: 1.4963 - val_accuracy: 0.4562\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4608 - accuracy: 0.4225 - val_loss: 1.3884 - val_accuracy: 0.5191\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.3385 - accuracy: 0.5157 - val_loss: 1.2382 - val_accuracy: 0.6697\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.1746 - accuracy: 0.6152 - val_loss: 1.0746 - val_accuracy: 0.7708\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0243 - accuracy: 0.6747 - val_loss: 0.9232 - val_accuracy: 0.8202\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.8833 - accuracy: 0.7522 - val_loss: 0.7871 - val_accuracy: 0.8607\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.7755 - accuracy: 0.7781 - val_loss: 0.6755 - val_accuracy: 0.8876\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.6530 - accuracy: 0.8371 - val_loss: 0.5837 - val_accuracy: 0.8966\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.5759 - accuracy: 0.8551 - val_loss: 0.5143 - val_accuracy: 0.9056\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 0.5018 - accuracy: 0.8702 - val_loss: 0.4626 - val_accuracy: 0.9034\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.4446 - accuracy: 0.9011 - val_loss: 0.4149 - val_accuracy: 0.9101\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 0.3983 - accuracy: 0.9017 - val_loss: 0.3813 - val_accuracy: 0.9169\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.3592 - accuracy: 0.9056 - val_loss: 0.3562 - val_accuracy: 0.9146\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.9230 - val_loss: 0.3312 - val_accuracy: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f858b9d0190>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=get_model()\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=thecallback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer!1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 7s 113ms/step - loss: 1.7632 - accuracy: 0.2539 - val_loss: 1.7234 - val_accuracy: 0.3730\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 1.6835 - accuracy: 0.3022 - val_loss: 1.6340 - val_accuracy: 0.3663\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.6039 - accuracy: 0.3371 - val_loss: 1.5558 - val_accuracy: 0.4180\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.5220 - accuracy: 0.4129 - val_loss: 1.4632 - val_accuracy: 0.5011\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.4282 - accuracy: 0.4663 - val_loss: 1.3449 - val_accuracy: 0.5730\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.2896 - accuracy: 0.5669 - val_loss: 1.1983 - val_accuracy: 0.6247\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.1471 - accuracy: 0.6298 - val_loss: 1.0460 - val_accuracy: 0.7663\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.9934 - accuracy: 0.6966 - val_loss: 0.8934 - val_accuracy: 0.8404\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.8369 - accuracy: 0.7685 - val_loss: 0.7632 - val_accuracy: 0.8584\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.7307 - accuracy: 0.8112 - val_loss: 0.6561 - val_accuracy: 0.8719\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.6224 - accuracy: 0.8461 - val_loss: 0.5766 - val_accuracy: 0.8854\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.8691 - val_loss: 0.5077 - val_accuracy: 0.8944\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.8938 - val_loss: 0.4501 - val_accuracy: 0.8989\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.9011 - val_loss: 0.4094 - val_accuracy: 0.9056\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.3567 - accuracy: 0.9135 - val_loss: 0.3793 - val_accuracy: 0.9079\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.3250 - accuracy: 0.9157 - val_loss: 0.3588 - val_accuracy: 0.9079\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.2974 - accuracy: 0.9270 - val_loss: 0.3413 - val_accuracy: 0.9056\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.2669 - accuracy: 0.9410 - val_loss: 0.3207 - val_accuracy: 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/conda3.9/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================================================\n",
    "# PROBLEM B4\n",
    "#\n",
    "# Build and train a classifier for the BBC-text dataset.\n",
    "# This is a multiclass classification problem.\n",
    "# Do not use lambda layers in your model.\n",
    "#\n",
    "# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n",
    "#\n",
    "# Desired accuracy and validation_accuracy > 91%\n",
    "# ===================================================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def solution_B4():\n",
    "    bbc = pd.read_csv('https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n",
    "\n",
    "    # DO NOT CHANGE THIS CODE\n",
    "    # Make sure you used all of these parameters or you can not pass this test\n",
    "    vocab_size = 1000\n",
    "    embedding_dim = 16\n",
    "    max_length = 120\n",
    "    trunc_type = 'post'\n",
    "    padding_type = 'post'\n",
    "    oov_tok = \"<OOV>\"\n",
    "    training_portion = .8\n",
    "    \n",
    "    #decode to ordinal\n",
    "    replacer=dict(zip(bbc[\"category\"].unique(), list(range(len(bbc[\"category\"].unique())))))\n",
    "    bbc[\"category\"]=bbc[\"category\"].replace(replacer)\n",
    "    \n",
    "    #train test split\n",
    "    training_sentences, validation_sentences, training_labels, validation_labels= train_test_split(bbc[\"text\"].to_numpy(), bbc[\"category\"].to_numpy(), train_size=training_portion, shuffle=False)\n",
    "\n",
    "    #the token\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok, num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(training_sentences)\n",
    "    \n",
    "    def get_paddedsequences(sentences):\n",
    "        sequences = tokenizer.texts_to_sequences(sentences)\n",
    "        return pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    training_pad_sequences=get_paddedsequences(training_sentences)\n",
    "    validation_pad_sequences=get_paddedsequences(validation_sentences)\n",
    "\n",
    "    def get_ds(the_padsequences, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((the_padsequences, labels))\n",
    "        ds = ds.cache()\n",
    "        ds = ds.batch(32)\n",
    "        return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = get_ds(training_pad_sequences, training_labels)\n",
    "    val_ds = get_ds(validation_pad_sequences, validation_labels)\n",
    "\n",
    "    def get_model():\n",
    "        model=keras.Sequential([\n",
    "            keras.layers.Embedding(input_dim=vocab_size, input_length=max_length, output_dim=embedding_dim),\n",
    "            keras.layers.GlobalAvgPool1D(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(32, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.3),        \n",
    "            keras.layers.Dense(6, activation='softmax')\n",
    "        ])   \n",
    "        model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.sparse_categorical_crossentropy, metrics=\"accuracy\")\n",
    "        return model\n",
    "    \n",
    "    class thecallback(tf.keras.callbacks.Callback):\n",
    "        def __init__(self):\n",
    "            super(thecallback, self).__init__()\n",
    "            \n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            logtrain, logval = logs[\"accuracy\"], logs[\"val_accuracy\"]\n",
    "            if logtrain > 0.91 and logval> 0.91:\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "    model=get_model()\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=thecallback())\n",
    "\n",
    "    return model\n",
    "\n",
    "    # The code below is to save your model as a .h5 file.\n",
    "    # It will be saved automatically in your Submission folder.\n",
    "if __name__ == '__main__':\n",
    "    # DO NOT CHANGE THIS CODE\n",
    "    model = solution_B4()\n",
    "    model.save(\"Model/model_B4.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
