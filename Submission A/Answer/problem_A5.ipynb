{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================================\n",
    "# PROBLEM A5\n",
    "#\n",
    "# Build and train a neural network model using the Sunspots.csv dataset.\n",
    "# Use MAE as the metrics of your neural network model.\n",
    "# We provided code for normalizing the data. Please do not change the code.\n",
    "# Do not use lambda layers in your model.\n",
    "#\n",
    "# The dataset used in this problem is downloaded from kaggle.com/robervalt/sunspots\n",
    "#\n",
    "# Desired MAE < 0.15 on the normalized dataset.\n",
    "# ========================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "True\n",
      "3.9.18 (main, Sep 11 2023, 13:41:44) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "#Check for GPU support, tf and python ver\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust performance and make series as tf.dataset\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sunspots.csv'\n",
    "urllib.request.urlretrieve(data_url, 'sunspots.csv')\n",
    "\n",
    "# Get data of sunspots and time_step from the dataset\n",
    "time_step = []; sunspots = []\n",
    "with open('sunspots.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        sunspots.append(row[2])\n",
    "        time_step.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "series=np.array(sunspots, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization Function. DO NOT CHANGE THIS CODE\n",
    "min=np.min(series)\n",
    "max=np.max(series)\n",
    "series -= min\n",
    "series /= max\n",
    "time=np.array(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CODE\n",
    "split_time=3000\n",
    "\n",
    "# splitting\n",
    "time_train =  time[:split_time]\n",
    "x_train =  series[:split_time]\n",
    "time_valid =  time[split_time:]\n",
    "x_valid = series[split_time:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 00:31:12.057055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.259192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.259256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.267529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.267627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.267660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.691144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.691605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.691651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-16 00:31:12.691771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-16 00:31:12.692953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#Const\n",
    "window_size=30\n",
    "batch_size=32\n",
    "shuffle_buffer_size=1000\n",
    "\n",
    "# Get train_ds\n",
    "train_set=windowed_dataset(x_train, window_size=window_size,\n",
    "                            batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thecustomcallbacks(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(thecustomcallbacks, self).__init__()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loggedtrain = logs[\"mae\"]\n",
    "        if loggedtrain < 0.15:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(None, 1)),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, \"relu\")        #Regression\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MSE, metrics = \"mae\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 5s 16ms/step - loss: 0.0108 - mae: 0.0744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9d0e313d60>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=get_model()\n",
    "model.fit(train_set, epochs=10, callbacks=[thecustomcallbacks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 4s 16ms/step - loss: 0.0108 - mae: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 00:50:48.640088: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 12407606590902358939\n",
      "/root/miniconda3/envs/conda3.9/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================================\n",
    "# PROBLEM A5\n",
    "#\n",
    "# Build and train a neural network model using the Sunspots.csv dataset.\n",
    "# Use MAE as the metrics of your neural network model.\n",
    "# We provided code for normalizing the data. Please do not change the code.\n",
    "# Do not use lambda layers in your model.\n",
    "#\n",
    "# The dataset used in this problem is downloaded from kaggle.com/robervalt/sunspots\n",
    "#\n",
    "# Desired MAE < 0.15 on the normalized dataset.\n",
    "# ========================================================================================\n",
    "\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "# DO NOT CHANGE THIS CODE\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "  series = tf.expand_dims(series, axis=-1)\n",
    "  ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "  ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "  ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "  ds = ds.shuffle(shuffle_buffer)\n",
    "  ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "  return ds.batch(batch_size).prefetch(1)\n",
    "\n",
    "\n",
    "def solution_A5():\n",
    "  data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sunspots.csv'\n",
    "  urllib.request.urlretrieve(data_url, 'sunspots.csv')\n",
    "\n",
    "  time_step = []\n",
    "  sunspots = []\n",
    "  with open('sunspots.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "      sunspots.append(row[2])\n",
    "      time_step.append(row[0])\n",
    "\n",
    "  series = np.array(sunspots, dtype=float)\n",
    "\n",
    "  # Normalization Function. DO NOT CHANGE THIS CODE\n",
    "  min=np.min(series)\n",
    "  max=np.max(series)\n",
    "  series -= min\n",
    "  series /= max\n",
    "  time=np.array(time_step)\n",
    "\n",
    "  # DO NOT CHANGE THIS CODE\n",
    "  split_time=3000\n",
    "\n",
    "  time_train =  time[:split_time]\n",
    "  x_train =  series[:split_time]\n",
    "  time_valid =  time[split_time:]\n",
    "  x_valid = series[split_time:]\n",
    "\n",
    "  # DO NOT CHANGE THIS CODE\n",
    "  window_size=30\n",
    "  batch_size=32\n",
    "  shuffle_buffer_size=1000\n",
    "\n",
    "  train_set=windowed_dataset(x_train, window_size=window_size,\n",
    "                              batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n",
    "\n",
    "  class thecustomcallbacks(tf.keras.callbacks.Callback):\n",
    "      def __init__(self):\n",
    "          super(thecustomcallbacks, self).__init__()\n",
    "      \n",
    "      def on_epoch_end(self, epoch, logs=None):\n",
    "          loggedtrain = logs[\"mae\"]\n",
    "          if loggedtrain < 0.15:\n",
    "              self.model.stop_training = True\n",
    "            \n",
    "  def get_model():\n",
    "      model=tf.keras.Sequential([\n",
    "          tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(None, 1)),\n",
    "          tf.keras.layers.LSTM(64),\n",
    "          tf.keras.layers.Dropout(0.2),\n",
    "          tf.keras.layers.Dense(1, \"relu\")        #Regression\n",
    "      ])\n",
    "      model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MSE, metrics = \"mae\")\n",
    "      \n",
    "      return model\n",
    "  \n",
    "  model=get_model()\n",
    "  model.fit(train_set, epochs=10, callbacks=[thecustomcallbacks()])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "# The code below is to save your model as a .h5 file.\n",
    "# It will be saved automatically in your Submission folder.\n",
    "if __name__ == '__main__':\n",
    "    # DO NOT CHANGE THIS CODE\n",
    "    model=solution_A5()\n",
    "    model.save(\"model_A5.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
